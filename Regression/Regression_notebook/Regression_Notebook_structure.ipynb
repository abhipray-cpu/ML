{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydzB3yQdMtzk"
      },
      "source": [
        "# **This notebook contains all the basic regression tools I use for my work.This will be modified with time and it's repo and previous copies are available in my github account**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzIQDJkDMkqw"
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2tBZ2PAS06Q"
      },
      "source": [
        "#generate your dataset\n",
        "def generate_data(location:str,sample_number=10):\n",
        "  data=pd.read_csv(location)\n",
        "  head=data.head()\n",
        "  tail=data.tail()\n",
        "  sample=data.sample(sample_number)\n",
        "  description=data.describe()\n",
        "  columns=data.columns\n",
        "  info=data.info()\n",
        "  shape=data.shape\n",
        "  size=data.size\n",
        "  return {'data':data,'head':head,'tail':tail,'sample':sample,'description':description,'columns':columns,'info':info,\n",
        "          'shape':shape,'size':size}\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVEjNyazT4My"
      },
      "source": [
        "data_set=generate_data('/content/Life Expectancy Data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYBgeaoVU2mB"
      },
      "source": [
        "# check for null values and deal with them\n",
        "# this function will take the type of process as well for both numeric and categorical data\n",
        "def treat_null_values(numeric_type:str='mean',categorical_type:str='frequent'):\n",
        "  pass "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiiWmI1fU2xH"
      },
      "source": [
        "def encode_data(data,multiclass:str='One_hot',binary_class:str='Label'): #this function takes three args one is the data 2nd is the type of encoding for multiclass data and third is the encoding for binary class data\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOPdhVnNU26j"
      },
      "source": [
        "def treat_outliers(data,algo:str='IQR'): # this function takes two arguments one is data and 2ns is the algorithm\n",
        "  pass\n",
        "# this will function will be returning two datasets the original one and one in which all the outliers are removed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db-FLeQaixXz"
      },
      "source": [
        "def balance_data(data):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdJVdqMDT3KN"
      },
      "source": [
        "# this function will perform all the data preprocessing steps\n",
        "def preprocess_data(data):\n",
        "  data=treat_null_values()\n",
        "  data=encode_data()\n",
        "  data=treat_outliers()\n",
        "  data=balance_data()\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uet5Gv-emDTd"
      },
      "source": [
        "#this function will check for collinearity and treat it as well\n",
        "def check_coolinearity(data):\n",
        "  pass\n",
        "# this will will also return two dataset one being the original one and second one will be the one in\n",
        "# which all the coolinear features will be treated:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhwW-nxomiVL"
      },
      "source": [
        "def feature_engineering(data):\n",
        "  # in this function do all the feature enginerring stuff you want to do"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vHaU7v5jrQ1"
      },
      "source": [
        "#visualize your data using this function\n",
        "#in all the functions pass folparameters\n",
        "'''\n",
        "1)type of plot\n",
        "2)feature that will be used in x_axis\n",
        "3)featur that will be used in y_axis\n",
        "4)parametres that will be used while drawing the plot\n",
        "'''\n",
        "def matplot_lib_visualize(type:str,x:str,y:str,*params): \n",
        "  pass\n",
        "def seaborn_visualize(type:str,x:str,y:str,*params):\n",
        "  pass\n",
        "def plotly_visualize(type:str,x:str,y:str,*params):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP659gTAl4MT"
      },
      "source": [
        "#Prepare a descriptive table in here on how to use this function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAeY4fsam0ab"
      },
      "source": [
        "def split_datad(data,test_data_percentage=0.25,random_state=42):\n",
        "  pass\n",
        "# this function takes three args one being the data and other the percent of test data and the random_state\n",
        "# this function will return 4 args x_train,x_test,y_train,y_test\n",
        "# add shape and size as well for all the params\n",
        "# in this format \n",
        "#{'x_train':{\"data\":data,\"shape\":data.shape,\"size\":data.size}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyUo20z3mrwB"
      },
      "source": [
        "def scale_data(x_train,x_test,type:str='Standard'):\n",
        "  pass\n",
        " # this function takes three args x_train,x_test and the type of scaling that should be applied\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF1_WBWXneFA"
      },
      "source": [
        "def prepate_model(x_train,y_train):\n",
        "  pass\n",
        "  #prepare all the models\n",
        "# this function will return a dictionary of models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMyujlsUpV9u"
      },
      "source": [
        "def make_predictios(models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy6FhtMMobqy"
      },
      "source": [
        "def concate_test_pred(predictions,y_test):\n",
        "  pass\n",
        "  #this function will return  a dictionary containing the concatenated list of y_test and y_pred for each model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnzu66tYoC22"
      },
      "source": [
        "def visualize_models(y_test,models):\n",
        "  pass\n",
        "#models here is a dict of models using which models will be evaluated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIl4tBN4qg8C"
      },
      "source": [
        "def r2_score_models(models,x_train,y_train):\n",
        "  pass\n",
        "# in this function prepare a dictionary for all the models and the dict will include the mean r2 and the r2 score list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ews4ewzGoqxx"
      },
      "source": [
        "def model_evaluation(models,x_train,y_train):\n",
        "  pass\n",
        "# this function will return a dataframe including the different matrices on basis of which a model should be evaluted\n",
        "# foe each model\n",
        "# use k-fold cross validation here\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iznM6R9hpH1H"
      },
      "source": [
        "def study_model(models):\n",
        "  pass\n",
        "# use bootstrapping here two study the deviation and distrubution of params of each trained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXtn9wsFqzRe"
      },
      "source": [
        "def hypertune_model(model,*param_grid,cv=10,n_jobs=-1):\n",
        "  pass\n",
        "# this function will accept a model and all the configurable hyperparametres and will return the tuned model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2RfQHpGrgS1"
      },
      "source": [
        "#prepare a dictionary that will containt the hyperparametes for all the models and can be easily accessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5eV6Gv9rtfU"
      },
      "source": [
        "def reduce_dimension(algo:str='PCA',kernel:str='rbf'):\n",
        "  pass\n",
        "  # this function will return a new dataset with reduced dimensions in case you want to reduce dimension"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}