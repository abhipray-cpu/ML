# -*- coding: utf-8 -*-
"""Time series model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11pb7qrmQxNQ1RwYLYU9zyEO2xC2D9VER

# **This is the time series model for the stock prediction dataset**
"""

!pip install plotly --upgrade

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

filepath = '/content/AABA_2006-01-01_to_2018-01-01.csv'
stock = pd.read_csv(filepath, parse_dates=['Date'], index_col='Date')
print(stock.shape)  # (123, 8)
stock.tail()

def visualuze_multivariate_time_series(data,rows:int=3,cols:int=2):
  fig, axes = plt.subplots(nrows=rows, ncols=cols, dpi=120, figsize=(10,6))
  # i will simply give the column count/index
  for i, ax in enumerate(axes.flatten()):
    df = data[data.columns[i]]
    ax.plot(df, color='red', linewidth=1)
    fig.tight_layout(pad=3.0)#this is for providing proper spacing between the plots
    # Decorations
    ax.set_title(data.columns[i])
    ax.xaxis.set_ticks_position('none')
    ax.yaxis.set_ticks_position('none')
    ax.spines["top"].set_alpha(0)
    ax.tick_params(labelsize=6)

stock.drop('Name',inplace=True,axis=1)

visualuze_multivariate_time_series(stock)

def grangers_causation_matrix(data, variables,maxlag:int=12, test:str='ssr_chi2test', verbose:bool=False):    
    """Check Granger Causality of all possible combinations of the Time series.
    The rows are the response variable, columns are predictors. The values in the table 
    are the P-Values. P-Values lesser than the significance level (0.05), implies 
    the Null Hypothesis that the coefficients of the corresponding past values is 
    zero, that is, the X does not cause Y can be rejected.

    data      : pandas dataframe containing the time series variables
    variables : list containing names of the time series variables.
    """
    from statsmodels.tsa.stattools import grangercausalitytests
    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)
    for c in df.columns:
        for r in df.index:
            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)
            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]
            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')
            min_p_value = np.min(p_values)
            df.loc[r, c] = min_p_value
    df.columns = [var + '_x' for var in variables]
    df.index = [var + '_y' for var in variables]
    return df


#how to read this table?
'''
If a given p-value is < significance level (0.05), 
then, the corresponding X time series (column) causes/effects the Y time series (row).
'''

grangers_causation_matrix(stock, variables = stock.columns)

def cointegration_test(df, alpha=0.05):
  from statsmodels.tsa.vector_ar.vecm import coint_johansen 
  """Perform Johanson's Cointegration Test and Report Summary"""
  out = coint_johansen(df,-1,5)
  d = {'0.90':0, '0.95':1, '0.99':2}
  traces = out.lr1
  cvts = out.cvt[:, d[str(1-alpha)]]
  def adjust(val, length= 6): return str(val).ljust(length)
  # Summary
  print('Name   ::  Test Stat > C(95%)    =>   Signif  \n', '--'*20)
  for col, trace, cvt in zip(df.columns, traces, cvts):
    print(adjust(col), ':: ', adjust(round(trace,2), 9), ">", adjust(cvt, 8), ' =>  ' , trace > cvt)

cointegration_test(stock)

#splitting the dataset into train and test set
nobs = 500 #this is the numbe of elements that will be contained in the test set
stock_train, stock_test = stock[0:-nobs], stock[-nobs:]

# Check size
print(stock_train.shape)  # (119, 8)
print(stock_test.shape)  # (4, 8)

#checking for stationarity and making the time series stationary
#implementing ADFuller test with significance/threshold value of 0.5
def adfuller_test(series, signif=0.05, name='', verbose=False):
  from statsmodels.tsa.stattools import adfuller
  """Perform ADFuller to test for Stationarity of given series and print report"""
  r = adfuller(series, autolag='AIC')
  output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}
  p_value = output['pvalue'] 
  def adjust(val, length= 6): return str(val).ljust(length)
  # Print Summary
  print(f'    Augmented Dickey-Fuller Test on "{name}"', "\n   ", '-'*47)
  print(f' Null Hypothesis: Data has unit root. Non-Stationary.')
  print(f' Significance Level    = {signif}')
  print(f' Test Statistic        = {output["test_statistic"]}')
  print(f' No. Lags Chosen       = {output["n_lags"]}')
  for key,val in r[4].items():
    print(f' Critical value {adjust(key)} = {round(val, 3)}')
  
  if p_value <= signif:
    print(f" => P-Value = {p_value}. Rejecting Null Hypothesis.")
    print(f" => Series is Stationary.")
  else:
    print(f" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.")
    print(f" => Series is Non-Stationary.")

#implementing ADFuller test on each column
for name, column in stock_train.iteritems():
    adfuller_test(column, name=column.name)
    print('\n')

#since none of the time series is stationaty therefore differencing all of them
stock_differenced = stock_train.diff().dropna()
#AD Fuller test on each of the tim series
for name, column in stock_differenced.iteritems():
    adfuller_test(column, name=column.name)
    print('\n')

#All the time series are stationary now we can proceed
#How to select the right order P of the var model
def check_lag(data):
  from statsmodels.tsa.api import VAR
  model = VAR(data)
  for i in [1,2,3,4,5,6,7,8,9]:
    result = model.fit(i)
    print('Lag Order =', i)
    print('AIC : ', result.aic)
    print('BIC : ', result.bic)
    print('FPE : ', result.fpe)
    print('HQIC: ', result.hqic, '\n')

# we select the model and one of the criteria is BIC the value in inversely proportional to the performance of the model
check_lag(stock_differenced)

#based on the above function the lag order is 6
#or we can use this function
def check_lag_auto(data,maxlags:int=12):
  from statsmodels.tsa.api import VAR
  model = VAR(stock_differenced)
  x = model.select_order(maxlags=12)
  display(x.summary())

check_lag_auto(stock_differenced)

#going with lag order 6
#selecting the lag 4 since it is giving the best results
def train_model(data,lag:int):
  from statsmodels.tsa.api import VAR
  model = VAR(data)
  model_fitted = model.fit(lag)
  return model_fitted

var_model = train_model(stock_differenced,6)
var_model.summary()

'''
The value of this statistic can vary between 0 and 4.
 The closer it is to the value 2, then there is no 
 significant serial correlation. 
 The closer to 0, there is a positive serial correlation,
  and the closer it is to 4 implies negative serial correlation.
'''
from statsmodels.stats.stattools import durbin_watson
out = durbin_watson(var_model.resid)

for col, val in zip(stock.columns, out):
    print(col, ':', round(val, 2))

#forecasting using varModel
# Get the lag order
lag_order = var_model.k_ar
print(lag_order)  #> 4

# Input data for forecasting
forecast_input = stock_differenced.values[-lag_order:]
forecast_input

#forecast
fc = var_model.forecast(y=forecast_input, steps=nobs)
df_forecast = pd.DataFrame(fc, index=stock.index[-nobs:], columns=stock.columns + '_2d')
df_forecast

#invert the transformation to get the real data
def invert_transformation(df_train, df_forecast, second_diff=False):
    """Revert back the differencing to get the forecast to original scale."""
    df_fc = df_forecast.copy()
    columns = df_train.columns
    for col in columns:        
        # Roll back 2nd Diff
        if second_diff:
            df_fc[str(col)+'_1d'] = (df_train[col].iloc[-1]-df_train[col].iloc[-2]) + df_fc[str(col)+'_2d'].cumsum()
        # Roll back 1st Diff
        df_fc[str(col)+'_forecast'] = df_train[col].iloc[-1] + df_fc[str(col)+'_1d'].cumsum()
    return df_fc

df_results = invert_transformation(stock_train, df_forecast, second_diff=True)

df_results.columns

df_results.loc[:, ['Open_forecast', 'High_forecast', 'Low_forecast', 'Close_forecast',
                   'Volume_forecast',]]

#Plotting forecast vs actual data
fig, axes = plt.subplots(nrows=int(len(stock.columns)/2), ncols=2, dpi=150, figsize=(15,20))
for i, (col,ax) in enumerate(zip(stock.columns, axes.flatten())):
    df_results[col+'_forecast'].plot(legend=True, ax=ax).autoscale(axis='x',tight=True)
    stock_test[col][-nobs:].plot(legend=True, ax=ax);
    fig.tight_layout(pad=3.0)
    ax.set_title(col + ": Forecast vs Actuals")
    ax.xaxis.set_ticks_position('none')
    ax.yaxis.set_ticks_position('none')
    ax.spines["top"].set_alpha(0)
    ax.tick_params(labelsize=6)

#the results do not match at all?
#since this is a volatile dataset therfore we need to use ARCH or GARCH model for predicting the stock price.