# -*- coding: utf-8 -*-
"""Classification_notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xk-fHJFfm9JOWMj2U-PdwT0gM2aV1kkt

# **This notebook contains all the tools I used for my classification models**
"""

#importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
sns.set(style="darkgrid")

#generate your dataset
def generate_data(location:str,sample_number=10):
  data=pd.read_csv(location,engine='python')
  head=data.head()
  tail=data.tail()
  sample=data.sample(sample_number)
  description=data.describe()
  columns=data.columns
  info=data.info()
  shape=data.shape
  size=data.size
  return_data = {'data':data,'head':head,'tail':tail,'sample':sample,'description':description,'columns':columns,'info':info,
          'shape':shape,'size':size}
  return return_data

data_set=generate_data('/content/data.csv')
data=data_set['data']

data.head()

def get_type(data):
  numeric=[]
  categorical=[]
  for col in data.columns:
    if data[f'{col}'].dtypes == 'object':
      categorical.append(col)
    else:
      numeric.append(col)
  return {'numeric':numeric,'categorical':categorical}

# check for null values and deal with them
# this function will take the type of process as well for both numeric and categorical data
def treat_null_values(data,numeric_type:str='mean'):
  types=get_type(data)
  numeric=types['numeric']
  categorical=types['categorical']
  if numeric_type == 'mean':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].fillna(data[f'{col}'].mean())
  elif numeric_type == 'mode':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].fillna(data[f'{col}'].mode())
  elif numeric_type == 'median':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].fillna(data[f'{col}'].median())
  elif numeric_type == 'frequent':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].fillna(data[f'{col}'].nunique[0])
  elif numeric_type == 'drop':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].dropnna(inplace=True)
  elif numeric_type == 'predictive_modeling':
    pass # create a seprate function for this
  elif numeric_type == 'impute':
    pass # create a seprate function for this as well
  
  for col in categorical:
    most_frequent_category=data[f'{col}'].mode()[0]
    data[f'{col}'].fillna(most_frequent_category,inplace=True)
  return data

  

def predictive_modeling():
  pass #do a detailed study as disadvantages for this model usually outweights advantages
def multiple_imputation():
  from fancyimpute import IterativeImputer as MICE
  data= pd.DataFrame(MICE().fit_transform(data))
  return data

def encode_data(data,multiclass:str='One_hot',binary_class:str='Label'): #this function takes three args one is the data 2nd is the type of encoding for multiclass data and third is the encoding for binary class data
  categorical=get_type(data)['categorical']
  multivariate=[]
  bivariate=[]
  for col in categorical:
    if data[f'{col}'].nunique()>2:
      multivariate.append(col)
    else:
      bivariate.append(col)
  
  if multiclass == 'One_hot':
    for col in multivariate:
      data=encode_and_bind(data,col)
  if binary_class == 'Label':
    for col in bivariate:
      data=label_encode(data,col)
  # add other sorting techniques as well in here
  return data

def encode_and_bind(original_dataframe, feature_to_encode):
    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])
    res = pd.concat([original_dataframe, dummies], axis=1)
    res.pop(feature_to_encode)
    return(res)

def label_encode(data,col):
  from sklearn.preprocessing import LabelEncoder
  encoder=LabelEncoder()
  data[col]=encoder.fit_transform(data[col])
  return data
  
# this function needs to be modified therefore add differenr sort of encoding techniques as well in this cll

def treat_outliers(data,feature:str,algo:str='IQR',z_threshold:int=3,add_feature=None,remove:bool=False,scatter:bool=False,feature_x=None,feature_y=None): # this function takes two arguments one is data and 2ns is the algorithm
  pass
  if scatter == True:
    px.scatter(data_px,x=feature_x,y=feature_y,hover_name='Country')
  else:
    if algo == 'IQR':
      outlier_index=Inter_quantile_range(data,feature)
    if algo == 'EEA': # elliptic envelope algo
      outlier_index=Elliptice_envelope_algo(data,feature,add_feature)
    if algo == 'ISF': # Isolate forest algo
      outlier_index=Isolate_forest_algo(data,feature)
    if algo == 'One_classSVM': # one class svm
      outlier_index=One_class_SVM(data,feature)
    if algo == 'LOF':
      outlier_index=Local_factor_outlier(data,feature)
    if algo == 'Z_score':
      outlier_index=Z_score_algo(data,feature,z_threshold)
    print(outlier_index)
    if remove == True:
      data=remove_outliers(outlier_index,data)
    
    return data
    


# in all these function display the index of outliers

def Local_factor_outlier(data,feature):
  import numpy as np 
  from sklearn.neighbors import LocalOutlierFactor
  X=data[[feature,data.columns.values[-1]]]
  lof = LocalOutlierFactor(n_neighbors=20, algorithm='auto',
                         metric='minkowski', contamination=0.04,
                         novelty=False, n_jobs=-1)
  pred = lof.fit_predict(X)
  outlier_index = np.where(pred==-1)
  return outlier_index

def One_class_SVM(data,feature): #this returns novelty I am guessing so fuck this method
  import numpy as np
  from sklearn.svm import OneClassSVM
  X=data[[feature,data.columns.values[-1]]]
  one_class_svm = OneClassSVM(kernel='rbf', degree=3, gamma='scale')
  new_data = np.array([[-4, 8.5]])# change these values as per your dataset
  one_class_svm.fit(X)
  pred = one_class_svm.predict(new_data)
  outlier_index = np.where(pred==-1)
  return outlier_index

def Isolate_forest_algo(data,feature):
  import numpy as np
  from sklearn.ensemble import IsolationForest
  from sklearn.decomposition import PCA
  from sklearn.preprocessing import StandardScaler
  X=data[[feature,data.columns.values[-1]]]
   # Returns 1 of inliers, -1 for outliers
  iforest = IsolationForest(n_estimators=100, max_samples='auto', 
                          contamination=0.05, max_features=1.0, 
                          bootstrap=False, n_jobs=-1, random_state=1)
  pred = iforest.fit_predict(X)
 # Extract outliers
  outlier_index = np.where(pred==-1)
  return outlier_index

def Elliptice_envelope_algo(data,feature,add_feature):
  import numpy as np
  from sklearn.covariance import EllipticEnvelope
  elpenv = EllipticEnvelope(contamination=0.025, 
                          random_state=1)
  X=data[[feature,add_feature]]
# Returns 1 of inliers, -1 for outliers
  pred = elpenv.fit_predict(X)

# Extract outliers
  outlier_index = np.where(pred==-1)
  return outlier_index

def Inter_quantile_range(data,feature):
  Q1 = np.percentile(data[f'{feature}'], 25, interpolation = 'midpoint') 
  Q2 = np.percentile(data[f'{feature}'], 50, interpolation = 'midpoint') 
  Q3 = np.percentile(data[f'{feature}'], 75, interpolation = 'midpoint') 
  IQR = Q3 - Q1 
  low_lim = Q1 - 1.5 * IQR
  up_lim = Q3 + 1.5 * IQR
  outlier_index=[]
  for val in data[f'{feature}']:
    if val > up_lim or val <low_lim:
      outlier_index.append(data.index[data[f'{feature}'] == val].values[0])
  return outlier_index
         
def Z_score_algo(data,feature,z_threshold):
  mean = np.mean(data[f'{feature}'])
  std = np.std(data[f'{feature}'])
  print('mean of the dataset is', mean)
  print('std. deviation is', std)
  outlier_index = []
  for val in data[f'{feature}']:
    z = (val-mean)/std
    if z > z_threshold:
      outlier_index.append(data.index[data[f'{feature}'] == val].values[0])
  return outlier_index
  


# this function will remove the outliers if removal is allowed
def remove_outliers(index,data):
  for row in index:
    data.drop([row])
    print(f'dropped value at index {row}')
  return data

      

# if remove is true remove outliers else if it is false just return the index of outliers
# this will function will be returning two datasets the original one and one in which all the outliers are removed

# this function will perform all the data preprocessing steps
# incase you want to use non default algos call these function seprately
def preprocess_data(data,feature:str):
  data=treat_null_values(data)
  data=encode_data(data)
  last_column = data[feature]
  data.drop(feature, inplace=True, axis=1)
  data.insert(data.shape[1],feature,last_column)
  
  return data

# call outliers and balance function independentlu whenever you like and PS Fuck Roopa

data=preprocess_data(data,'diagnosis')
data.drop('Unnamed: 32',inplace=True,axis=1)
data.head()

def create_heat_map(data):
  #correalation between varaibles
  plt.figure(figsize=(24, 20))
  heatmap = sns.heatmap(data.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')
  heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);
  # save heatmap as .png file
  # dpi - sets the resolution of the saved image in dots/inches
  # bbox_inches - when set to 'tight' - does not allow the labels to be cropped
  plt.savefig('heatmap.png', dpi=300, bbox_inches='tight')# this will will also return two dataset one being the original one and second one will be the one in

raw_data=pd.read_csv('/content/data.csv',engine='python')
raw_data.drop('Unnamed: 32',inplace=True,axis=1)
create_heat_map(raw_data)

# drawing plots will be much easier in direct manner therfore refer to original regression databook 
def SNS_distplot(feature:str,color:str='green'):
  sns.distplot(data[feature],color=color)

def SNS_histlpot(feature:str,shade:bool=True,color:str='blue'):
  sns.kdeplot(data[feature],shade=shade,color=color)

def SNS_kdeplot(feature:str,shade:bool=True,color:str='red'):
  sns.kdeplot(data[feature],shade=shade,color=color)

def SNS_jointplot(x:str,y:str,kind:str='kde',color:str='red'):
  sns.jointplot(data=data,x=x,y=y,color=color,kind=kind)

def SNS_scatterplot(x:str,y:str,color:str='blue'):
  sns.scatterplot(data=data,x=x,y=y,color=color)

def SNS_regPlot(x:str,y:str,color:str='magenta'):
  sns.regplot(x=data[x],y=data[y],color=color)

def PX_scatter(data,x:str,y:str,color:str,size:str,hover:str,facet_col:str,size_max:int):
  px.scatter(data,x=x,y=y,color=color,size=size,size_max=size_max,hover_name=hover,
           facet_col=facet_col)

def PX_scatterAnimate(data,x:str,y:str,animation_frame:str,animation_group:str,size:str,color:str,hover:str,range_x:list,range_y:list,log_x:bool=False,size_max:int=50):
  px.scatter(data, x=x, y=y, animation_frame=animation_frame, animation_group=animation_group,
           size=size, color=color, hover_name=hover,
           log_x=log_x, size_max=size_max, range_x=range_x, range_y=range_y)
  
def PX_histogram(data,x:str,y:str,color:str,hover:str):
  px.histogram(data,x=x,y=y,color=color,hover_name=hover)

def PX_box(data,x:str,y:str,category:str,categories:list,color:str,orientation:str='h',notched:bool=False):
  px.box(data,x=x,y=y,color=color,orientation=orientation,notched=notched,
       category_orders={category:categories})

def PX_violin(data,x:str,y:str,color:str):
  px.violin(data,x=x,y=y,color=color,box=True,points='all')

def multiplot(features,type:str='dist',a:int=4,b:int=3):
  a = 4  # number of rows
  b = 3  # number of columns 
  c = 1  # initialize plot counter
  fig = plt.figure(figsize=(14,22))
  if type == 'dist':
    for feature in features:
      plt.subplot(a, b, c)
      plt.title(feature)
      ax1=sns.distplot(data[feature],hist=False,color="red",)
      c=c+1
      if c > a*b:
        break
  elif type == 'kde':
    for feature in features:
      plt.subplot(a, b, c)
      plt.title(feature)
      ax1=sns.kdeplot(data[feature],color="red",shade=True)
      c=c+1
      if c > a*b:
        break
  elif type == 'hist':
    for feature in features:
      plt.subplot(a, b, c)
      plt.title(feature)
      ax1=sns.histplot(data[feature],kde=True,color="red",)
      c=c+1
      if c > a*b:
        break
  elif type=='box':
    for feature in features:
      plt.subplot(a, b, c)
      plt.title(feature)
      ax1=sns.boxplot(data[feature],color="red",)
      c=c+1
      if c > a*b:
        break
    
def PX_chloropeth(data,location:str,color:str,hover:str,animation:str,projection:str):
  px.choropleth(data,locations=location,color=color,hover_name=hover,animation_frame=animation,
              color_continuous_scale=px.colors.sequential.Plasma,projection=projection)
  


'''
     These are all the projection options avaialble:
     'equirectangular', 'mercator', 'orthographic', 'natural earth', 'kavrayskiy7', 'miller',
      'robinson', 'eckert4', 'azimuthal equal area', 'azimuthal equidistant', 'conic equal area',
       'conic conformal', 'conic equidistant', 'gnomonic', 'stereographic', 'mollweide', 'hammer',
        'transverse mercator', 'albers usa', 'winkel tripel', 'aitoff', or 'sinusoidal'.
'''

data.columns

SNS_distplot('diagnosis')
#in the label encoding section find a way to return the original class as well

def study_distribution(data,color:str='red'):
  b=4
  a=data.shape[1]/4 + 1
  c=1
  fig = plt.figure(figsize=(14,22))
  for column in data.columns:
    plt.subplot(a+1, b, c)
    plt.title(column)
    ax1=sns.distplot(data[column],hist=False,color=color,label=column)
    c=c+1


study_distribution(data)

data.columns

#these are all the plotly graph available since they can't be accessed via functions(ptani q?)

#1)Scatter plot
px.scatter(data,x='radius_mean',y='texture_mean',color='area_worst',size='area_mean',size_max=10,hover_name='radius_worst',
           facet_col='diagnosis')

#2)Animated scatter plots
#this usually works well withh time contained data 
px.scatter(data,x='radius_mean',y='texture_mean',color='diagnosis',size='area_mean',size_max=50,hover_name='radius_mean',animation_frame="radius_worst",animation_group='smoothness_mean',log_x=False,range_x=[0,30], range_y=[0,40] )
#animation is the feature based in which groups will be partitioned
#animation group is the data_feature based on which data will be grouped
# we can sort the data based on year if you want to see normal order in herew

px.histogram(data,x='radius_mean',y='texture_mean',color='diagnosis',hover_name='radius_worst',)

px.box(data,x='radius_mean',y='texture_mean',color='diagnosis',orientation='h',
       category_orders={'diagnosis':['Belaine','Melanin']})

def get_type(threshold:int=75):
  val_count=data[data.columns[-1]].nunique()
  if val_count > 2:
    print("Multivariate")
    give_instances()
  elif val_count == 2:
    print("Bivaraite")
    balacing_required(75)
  else:
    print("Not enough instances for the classification")
  

# this function will basically return the instances of each class in case of multivariate and in case of bivariate yes or no based on some threshold
def balacing_required(threshold:int=75):
  count = data[data.columns[-1]].value_counts()
  class1 = count[0]
  class2 = count[1]
  if class1 >= class2:
    majority=class1
    minority=class2
  else:
    majority=class2
    minority=class1
  print(f"majority_instance:{majority} \n minority_instance:{minority}")
  if minority >= (threshold/100)*majority:
    print(f"balancing not required since minoriy is {(minority/majority)*100}% of majority")
  else:
    print(f"balancing  required since minoriy is {(minority/majority)*100}% of majority")
  SNS_distplot(data.columns[-1])

  
def give_instances():
  print(data[data.columns[-1]].value_counts())
  SNS_distplot(data.columns[-1])

get_type()

"""# **Dataset balancing as this step is importatnt in case of classification problems:**

#this cell contains different type of balancing techniques which will be called as per user input
"""

!pip install smote

#this function will draw a distribution of data points for us
def plot_2d_space(X, y, label='Classes'):   
  colors = ['#1F77B4', '#FF7F0E']
  markers = ['o', 's']
  plt.figure(figsize=(10,12))
  for l, c, m in zip(np.unique(y), colors, markers):
    plt.scatter(
            X[y==l, 0],
            X[y==l, 1],
            c=c, label=l, marker=m
        )
        
  plt.title(label)
  plt.legend(loc='upper right')
  plt.show()
  from sklearn.decomposition import PCA
  pca = PCA(n_components=2)
  X = pca.fit_transform(X)


def get_detailed_sampling(X,y):
  res=random_under_sampling(X,y)
  ros=random_over_sampling(X,y)
  tomek=tomek_under_sampling(X,y)
  cluster=cluster_centroid_under_sampling(X,y)
  smot = smote(X,y)
  adasyn = adaptive_synthetic_sampling(X,y)
  mixed = hybrid(X,y)

  return {'random_under_sampling':res[1],'random_over_sampling':ros[1],'tomek_under_sampling':tomek[1],
          'centroid_clustring_under_sampling':cluster[1],'smote':smot[1],'adaptive_synthetic_sampling':adasyn[1],'oversampling_then_undersampling':mixed[1]}


def draw_distribution_sampledData(X,y,color:str='blue'):
  data=get_detailed_sampling(X,y)
  plt.figure(figsize=(14,18))
  b=4
  a=4
  c=1
  for val in data:
    plt.subplot(a, b, c)
    plt.title(val)
    ax1=sns.distplot(data[val],hist=False,color=color,label=val)
    c=c+1


def random_under_sampling(X,y):
  from imblearn.under_sampling import RandomUnderSampler 
  rus = RandomUnderSampler(random_state=42)
  X_res, y_res = rus.fit_resample(X, y)
  print('Original dataset shape %s' % y.shape)
  print('Resampled dataset shape %s' % y_res.shape)
  plot_2d_space(X_res,y_res)
  return [X_res,y_res]

def random_over_sampling(X,y):
  from imblearn.over_sampling import RandomOverSampler
  ros = RandomOverSampler()
  X_ros, y_ros = ros.fit_sample(X, y)
  print(X_ros.shape[0] - X.shape[0], 'new random picked points')
  print('Original dataset shape %s' % y.shape)
  print('Resampled dataset shape %s' % y_ros.shape)
  plot_2d_space(X_ros,y_ros,'Random over sampling')
  return [X_ros,y_ros]

def tomek_under_sampling(X,y):
  from imblearn.under_sampling import TomekLinks
  tl = TomekLinks(sampling_strategy='majority')
  X_tl, y_tl= tl.fit_sample(X, y)
  print('Original dataset shape %s' % y.shape)
  print('Resampled dataset shape %s' % y_tl.shape)
  plot_2d_space(X_tl, y_tl, 'Tomek links under-sampling')
  return [X_tl,y_tl]

def cluster_centroid_under_sampling(X,y):
  from imblearn.under_sampling import ClusterCentroids
  cc = ClusterCentroids()
  X_cc, y_cc = cc.fit_sample(X, y)
  print('Original dataset shape %s' % y.shape)
  print('Resampled dataset shape %s' % y_cc.shape)
  plot_2d_space(X_cc, y_cc, 'Cluster Centroids under-sampling')
  return [X_cc,y_cc]

def smote(X,y):
  from imblearn.over_sampling import SMOTE
  X_resampled, y_resampled = SMOTE().fit_resample(X, y)
  print(X_resampled.shape[0] - X.shape[0], 'new synthetic  points')
  print('Original dataset shape %s' % y.shape)
  print('Resampled dataset shape %s' % y_resampled.shape)
  plot_2d_space(X_resampled, y_resampled, 'SMOTE over-sampling')
  return [X_resampled,y_resampled]

def adaptive_synthetic_sampling(X,y):
  from imblearn.over_sampling import ADASYN 
  X_resampled, y_resampled = ADASYN().fit_resample(X, y)
  print(X_resampled.shape[0] - X.shape[0], 'new synthetic  points')
  print('Original dataset shape %s' % y.shape)
  print('Resampled dataset shape %s' % y_resampled.shape)
  plot_2d_space(X_resampled, y_resampled, 'ADASYN over-sampling')
  return [X_resampled,y_resampled]


def hybrid(X,y,type:str='Tomek'):
  if type == 'ENN':
    from imblearn.combine import SMOTEENN
    smote_enn = SMOTEENN(random_state=0)
    X_resampled, y_resampled = smote_enn.fit_resample(X, y)
    print('Original dataset shape %s' % y.shape)
    print('Resampled dataset shape %s' % y_resampled.shape)
    plot_2d_space(X_resampled, y_resampled, 'SMOTEENN')
    return [X_resampled,y_resampled]

  elif type == 'Tomek':
    from imblearn.combine import SMOTETomek
    smote_tomek = SMOTETomek(random_state=0)
    X_resampled, y_resampled = smote_tomek.fit_resample(X, y)
    print('Original dataset shape %s' % y.shape)
    print('Resampled dataset shape %s' % y_resampled.shape)
    plot_2d_space(X_resampled, y_resampled, 'SmoteTomek')
    return [X_resampled,y_resampled]

x=data.iloc[:,:-1].values
y=data.iloc[:,-1].values
#draw_distribution_sampledData(x,y)

def split_data(data):
  x=data.iloc[:,:-1].values
  y=data.iloc[:,-1].values
  from sklearn.model_selection import train_test_split
  x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=42)

  return{'x_train':x_train,'x_test':x_test,'y_train':y_train,'y_test':y_test}

split=split_data(data)
x_train=split['x_train']
x_test=split['x_test']
y_train=split['y_train']
y_test=split['y_test']

def scale_data(x_train,x_test,type:str='Standard'):
  if type == 'Standard':
    from sklearn.preprocessing import StandardScaler
    sc=StandardScaler()
    x_train=sc.fit_transform(x_train)
    x_test=sc.transform(x_test)
  elif type == 'Normalize':
    pass
  
  return {'x_train':x_train,'x_test':x_test}
 # this function takes three args x_train,x_test and the type of scaling that should be applied

scaled=scale_data(x_train,x_test)
x_train=scaled['x_train']
x_test=scaled['x_test']

!pip install costcla

!pip install catboost

def create_model(model:str='all',neighbours:int=5,kernel:str='rbf',criterion:str='entropy',n_estimator:int=10):
  logistic_classifier = logistic_classification(x_train,y_train)
  support_vector_classifier = support_vector_classification(x_train,y_train)
  kernel_support_vector_classifier = kernelSVM_classification(x_train,y_train,kernel)
  KNN_classifier = KNN_classification(x_train,y_train,neighbours)
  naive_bayes_classifier = naive_bayes_classification(x_train,y_train)
  DT_classifier = DT_classification(x_train,y_train,criterion)
  RF_classifier = RF_classification(x_train,y_train,n_estimator,criterion)
  gaussian_classifier = gaussian_process(x_train,y_train)
  ridge_classifier = ridge_classification(x_train,y_train)
  lda_classifier = linear_discriminant_analysis(x_train,y_train)
  adaboost_classifier = adaboost_classification(x_train,y_train)
  gradient_boosting_classifier= gradient_boost_classification(x_train,y_train)
  qda_classifier = quadratic_discriminant_analysis(x_train,y_train) 
  et_classifier = extra_tree_classification(x_train,y_train)
  xgb_classifier = xgb_classification(x_train,y_train)
  lgb_classifier = light_gradient_boosting_classification(x_train,y_train)
  catboost_classifier = catboost_classification(x_train,y_train)

  if model == 'all':
    return {'logistic_classifier':logistic_classifier,'support_vector_classifier':support_vector_classifier,'KernelSVC':kernel_support_vector_classifier,
          'KNN':KNN_classifier,'naive_bayes_classifier':naive_bayes_classifier,'decision_tree_classifier':DT_classifier,'random_forest_classifier':RF_classifier,
          'gaussian_classifier':gaussian_classifier,'ridge_classifier':ridge_classifier,'linear_discriminant_classifier':lda_classifier,
          'adaboost_classifier':adaboost_classifier,
          'gradient_boosting_classifier':gradient_boosting_classifier,
          'quadratic_discriminant_analysis':qda_classifier,
          'extra_tree_classifier':et_classifier,'xgb_classsifier':xgb_classifier,
          'lgb_classifier':lgb_classifier,
          'catboost_classifier':catboost_classifier}
  elif model == 'logistic_classifier':
    return logistic_classifier
  elif model == 'support_vector_classifier':
    return support_vector_classifier
  elif model == 'kernelSVC':
    return kernel_support_vector_classifier
  elif model == 'KNN':
    return KNN_classifier
  elif model == 'naive_bayes_classifier':
    return naive_bayes_classifier
  elif model == 'decision_tree_classifier':
    return DT_classifier
  elif model == 'random_forest_classifier':
    return RF_classifier
  elif model == 'gaussian_classifier':
    return gaussian_classifier
  elif model == 'ridge_classifier':
    return ridge_classifier
  elif model == 'linear_discriminant_classifier':
    return lda_classifier
  elif model == 'adaboost_classifier':
    return adaboost_classifier
  elif model == 'gradient_boosting_classifier':
    return gradient_boosting_classifier
  elif model == 'quadratic_discriminant_analysis':
    return qda_classifier
  elif model == 'extra_tree_classifier':
    return et_classifier
  elif model == 'xgb_classsifier':
    return xgb_classsifier
  elif model == 'lgb_classifier':
    return lgb_classifier
  elif model == 'LC':
    return catboost_classifier
  

  




def logistic_classification(x_train,y_train):
  from sklearn.linear_model import LogisticRegression
  classifier = LogisticRegression(random_state=42)
  classifier.fit(x_train,y_train)
  return classifier

def support_vector_classification(x_train,y_train):
  from sklearn.svm import SVC
  classifier = SVC(kernel = 'linear',random_state=42)
  classifier.fit(x_train,y_train)
  return classifier

def kernelSVM_classification(x_train,y_train,kernel):
  from sklearn.svm import SVC
  classifier = SVC(kernel = kernel,random_state = 42)
  classifier.fit(x_train,y_train)
  return classifier

def KNN_classification(x_train,y_train,neighbours):
  from sklearn.neighbors import KNeighborsClassifier
  classifier = KNeighborsClassifier(n_neighbors = neighbours, metric = 'minkowski', p = 2)
  classifier.fit(x_train, y_train)
  return classifier

# study this class
def naive_bayes_classification(x_train,y_train):
  from sklearn.naive_bayes import GaussianNB
  classifier = GaussianNB()
  classifier.fit(x_train, y_train)
  return classifier

def DT_classification(x_train,y_train,criterion):
  from sklearn.tree import DecisionTreeClassifier
  classifier = DecisionTreeClassifier(criterion = criterion, random_state = 0)
  classifier.fit(x_train, y_train)
  return classifier

def RF_classification(x_train,y_train,n_estimator,criterion):
  from sklearn.ensemble import RandomForestClassifier
  classifier = RandomForestClassifier(n_estimators = n_estimator, criterion = criterion, random_state = 0)
  classifier.fit(x_train, y_train)
  return classifier

# study these model before hypertuning them
def gaussian_process(x_train,y_train):
  from sklearn.gaussian_process import GaussianProcessClassifier
  from sklearn.gaussian_process.kernels import RBF
  kernel = 1.0 * RBF(1.0)
  classifier = GaussianProcessClassifier(kernel=kernel,random_state=42)
  classifier.fit(x_train, y_train)
  return classifier

def ridge_classification(x_train,y_train):
  from sklearn.linear_model import RidgeClassifier
  classifier = RidgeClassifier()
  classifier.fit(x_train,y_train)
  return classifier 

def linear_discriminant_analysis(x_train,y_train):
  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
  classifier = LinearDiscriminantAnalysis()
  classifier.fit(x_train,y_train)
  return classifier

def adaboost_classification(x_train,y_train):
  from sklearn.ensemble import AdaBoostClassifier
  classifier = AdaBoostClassifier(n_estimators=100,random_state=42)
  classifier.fit(x_train,y_train)
  return classifier

def gradient_boost_classification(x_train,y_train):
  from sklearn.ensemble import GradientBoostingClassifier
  classifier = GradientBoostingClassifier(n_estimators=42,random_state=42)
  classifier.fit(x_train,y_train)
  return classifier

def quadratic_discriminant_analysis(x_train,y_train):
  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
  classifier = QuadraticDiscriminantAnalysis()
  classifier.fit(x_train,y_train)
  return classifier

def extra_tree_classification(x_train,y_train):
  from sklearn.ensemble import ExtraTreesClassifier
  classifier = ExtraTreesClassifier(n_estimators=100,random_state=42)
  classifier.fit(x_train,y_train)
  return classifier

def xgb_classification(x_train,y_train):
  from xgboost import XGBClassifier
  classifier = XGBClassifier()
  classifier.fit(x_train,y_train)
  return classifier

def light_gradient_boosting_classification(x_train,y_train):
  from lightgbm import LGBMClassifier
  classifier = LGBMClassifier()
  classifier.fit(x_train,y_train)
  return classifier

def catboost_classification(x_train,y_train):
  from catboost import CatBoostClassifier
  classifier = CatBoostClassifier()
  classifier.fit(x_train,y_train)
  return classifier


models = create_model()

def make_predictions(models):
  predictions={}
  for model in models:
    print(model)
    y_pred=models[model].predict(x_test)
    predictions[f'y_pred_{model}']=y_pred
  return predictions

predictions=make_predictions(models)

def compare_results(predictions):
  compare_predictions={}
  for prediction in predictions:
    y_pred=predictions[prediction]
    res=np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)
    compare_predictions[f'{prediction}_concatenated']=res
  return compare_predictions
  #this function will return  a dictionary containing the concatenated list of y_test and y_pred for each model

compared = compare_results(predictions)

def visualize_models(y_test,predictions):
  a = 5  # number of rows
  b = 5  # number of columns 
  c = 1  # initialize plot counter
  fig = plt.figure(figsize=(15,18))
  sns.set(rc={"figure.dpi":300, 'savefig.dpi':300})
  for prediction in predictions:
    plt.subplot(a, b, c)
    plt.title(f'{prediction}')
    ax1=sns.distplot(y_test,hist=False,color="r",label="actual value")
    sns.distplot(predictions[prediction],hist=False,color="b",label="predicted values",ax=ax1)
    c=c+1
    if c > a*b:
      break

visualize_models(y_test,predictions)

# call this method again for the hypertuned model you will be deploying
def prepare_confusion_matrix(models):
  from sklearn.model_selection import cross_val_predict
  from sklearn.metrics import plot_confusion_matrix
  plt.figure(figsize=(5, 8))
  for model in models:
    plot_confusion_matrix(models[model], x_test, y_test)
    plt.title(f"{model}")

prepare_confusion_matrix(models)

# apply cross validation for this
def ROC_Curve(predictions):
  import sklearn.metrics as metrics
  a = 5  # number of rows
  b = 5  # number of columns 
  c = 1  # initialize plot counter
  for prediction in predictions:
    fig = plt.figure(figsize=(15,18))
    plt.subplot(a, b, c)
    fpr, tpr, threshold = metrics.roc_curve(y_test, predictions[prediction])
    roc_auc = metrics.auc(fpr, tpr)
    plt.title(f'{prediction}')
    plt.plot(fpr, tpr, 'g', label = 'AUC = %0.2f' % roc_auc)
    c=c+1
    if c > a*b:
      break

ROC_Curve(predictions)

def AUC_curve(predictions):
  from sklearn import metrics
  a = 5  # number of rows
  b = 5  # number of columns 
  c = 1  # initialize plot counter
  for prediction in predictions:
    auc = metrics.roc_auc_score(y_test, predictions[prediction])
    false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, predictions[prediction])
    fig = plt.figure(figsize=(15,18))
    plt.subplot(a, b, c)
    plt.title(prediction)
    plt.plot(false_positive_rate, true_positive_rate, 'g')
    plt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgreen', alpha=0.7)
    plt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=12, weight='bold', color='blue')

AUC_curve(predictions)

def matric_evaluation_of_models(models):
  
  from sklearn.model_selection import cross_validate
  evaluation={}
  for model in models:
    f1 = cross_validate(estimator=models[model], X = x_train, y = y_train, cv = 10,verbose=0,scoring='f1')
    accuracy = cross_validate(estimator=models[model], X = x_train, y = y_train, cv = 10,verbose=0,scoring='accuracy')
    # probablity = True for svc classifier since log loss requires this probablity
    # log_loss = cross_validate(estimator=models[model], X = x_train, y = y_train, cv = 10,verbose=0,scoring='neg_log_loss')
    # use this metric for the tuned model and with svc try probality = true if you are going with this model
    precision = cross_validate(estimator=models[model], X = x_train, y = y_train, cv = 10,verbose=0,scoring='precision')
    recall = cross_validate(estimator=models[model], X = x_train, y = y_train, cv = 10,verbose=0,scoring='recall')
    auc = cross_validate(estimator=models[model], X = x_train, y = y_train, cv = 10,verbose=0,scoring='roc_auc')
    
    evaluation[model]={'f1':f1['test_score'].mean(),'accuracy':accuracy['test_score'].mean(),'precision':precision['test_score'].mean(),'recall':recall['test_score'].mean(),'auc':auc['test_score'].mean()}
  return evaluation

'''
1)Accuracy
2)Detection Rate

4)Senstivity(true positive rate)
5)Specificity(false positive rate)
6)Precision
7)Recall
8)F1 score(sort the data frame according to this metric)
Calculate these parameter on the trained and tuned model which you will be deploying
3)Log loss
9)Senstivity 
10)Specificity
'''

scores=matric_evaluation_of_models(models)
display(scores)

def prepare_df_model_evaluation(scores,sort:str='f1'):
  index=[]
  for i in range(0,len(scores)):
    index.append(i)
  columns=['model','accuracy','auc','f1','precision','recall']
  
  from sklearn.model_selection import cross_val_score
  data_score=[]
  for score in scores:
    data_premature=[]
    data_premature.append(score)
    data_premature.append(scores[score]['accuracy'])
    data_premature.append(scores[score]['auc'])
    data_premature.append(scores[score]['f1'])
    data_premature.append(scores[score]['precision'])
    data_premature.append(scores[score]['recall'])
    data_score.append(data_premature)
  score_data = pd.DataFrame(data=data_score,index=index,columns=columns)
  score_data = score_data.sort_values(by=[sort],ascending=False)
  return score_data

scores_data=prepare_df_model_evaluation(scores,'f1')#pass the second paramaetere as the sorting metrics
display(scores_data)

#Senstivity and sepecificity 
#this function works only for a simple model therfore no cross validation you can call this
#function on your tuned model which you will be deploying
def perf_measure(y_actual, y_hat):
    TP = 0
    FP = 0
    TN = 0
    FN = 0

    for i in range(len(y_hat)): 
        if y_actual[i]==y_hat[i]==1:
           TP += 1
        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:
           FP += 1
        if y_actual[i]==y_hat[i]==0:
           TN += 1
        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:
           FN += 1

    return(TP, FP, TN, FN)

def get_confusion_params(predictions):
  params={}
  for prediction in predictions:
    values =  perf_measure(y_test, predictions[prediction])
    TP,FP,TN,FN = values
    params[prediction]={'TP':TP,'FP':FP,'TN':TN,'FN':FN}
  return params

values=get_confusion_params(predictions)

def calculate_specificity(params):
  return params['TN']/(params['TN']+params['FP'])

def calculate_senstivity(params):
  return params['TN']/(params['TP']+params['FN'])

def specificity_senstivity(values):
  scoring_metric={}
  for val in values:
    specificity = calculate_specificity(values[val])
    senstivity = calculate_senstivity(values[val])
    scoring_metric[val]={'specificity':specificity,'senstivity':senstivity}
  return scoring_metric

scoring_metric = specificity_senstivity(values)
display(scoring_metric)

#log loss function
#note for this function probality=true for SVC models
#since this loss function works on probablity
#exclude SVC from this function if you are not using probablity = True
def calculate_log_loss(models):
  
  from sklearn.model_selection import cross_validate
  evaluation={}
  for model in models:
    # probablity = True for svc classifier since log loss requires this probablity
    log_loss = cross_validate(estimator=models[model], X = x_train, y = y_train, cv = 10,verbose=0,scoring='neg_log_loss')
    # use this metric for the tuned model and with svc try probality = true if you are going with this model
    evaluation[model]={'log_loss':log_loss}
  return evaluation

log_loss =  calculate_log_loss(models) # I repeat again Include SVC model only if you have probablity = true

def hypertune_model(model,x_train,y_train,scoring:str='f1'):
  if model == 'logistic_classifier':
    params_grid=LOGISTIC_REGRESSION()
    #'decision_function_shape':ovo or ovr, default is ovr you can compare the model with ovo if you want
  elif model == 'support_vector_classifier':
    params_grid=LINEAR_SVC()
  elif model == 'KernelSVC':
    params_grid = KERNEL_SVC()
  elif model == 'decision_tree_classifier':
    params_grid=DT_CLASSIFIER()
  elif model == 'random_forest_classifier':
    params_grid = RF_CLASSIFIER()
  elif model == 'KNN':
    params_grid=KNN_CLASSIFIER()
  elif model == 'gaussian_classifier':
    params_grid=GAUSSIAN_CLASSIFIER()
  elif model == 'ridge_classifier':
    params_grid = RIDGE_CLASSIFIER()
  elif model == 'linear_discriminant_classifier':
    params_grid = LDA_CLASSIFIER()
  elif model == 'adaboost_classifier':
    params_grid = ADABOOST_CLASSIFIER()
  elif model == 'gradient_boosting_classifier':
    params_grid = GRADIENT_BOOSTING_CLASSIFIER()
  elif model == 'quadratic_discriminant_analysis':
    params_grid = QDA_CLASSIFIER()
  elif model == 'extra_tree_classifier':
    params_grid = ET_CLASSIFIER()
  elif model == 'xgb_classsifier':
    params_grid = XGB_CLASSIFIER()
  elif model == 'lgb_classifier':
    params_grid = LGB_CLASSIFIER()
 
 
  
  print(models[model])
  from sklearn.model_selection import GridSearchCV
  grid=GridSearchCV(estimator=models[model],cv=10,verbose=20,n_jobs=-1,param_grid=params_grid,scoring=scoring)
  grid.fit(x_train,y_train)
  # Checking the score for all parameters
  print("Grid scores on training set:")
  means = grid.cv_results_['mean_test_score']
  stds = grid.cv_results_['std_test_score']
  for mean, std, params in zip(means, stds, grid.cv_results_['params']):
    print("%0.3f (+/-%0.03f) for %r"% (mean, std * 2, params))
  



def LOGISTIC_REGRESSION():
  c=[1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e1,1e2,1e3,1e4,1e5,1e6,1e7]
  penalty = ['l1', 'l2', 'elasticnet', 'none']
  tol=[1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]
  solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']
  multiclass = ['auto', 'ovr', 'multinomial']
  
  warm_start=[True,False]
 
  parameters={'C':c,'penalty':penalty,'tol':tol,'solver':solver,
          'multi_class':multiclass,'warm_start':warm_start,}
  return parameters


def LINEAR_SVC():
  c=[1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e1,1e2,1e3,1e4,1e5,1e6,1e7]
  shrinking=[True,False]
  probablity=[True,False]
  tol=[1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]
  decision_function_shape=['ovo','ovr']
  break_ties=[False,True]
  parameters=[{'C':c,'shrinking':shrinking,'probability':probablity,
          'tol':tol,'break_ties':break_ties},]
  return parameters

def KERNEL_SVC():
  c=[1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e1,1e2,1e3,1e4,1e5,1e6,1e7]
  tol=[1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]
  shrinking=[True,False]
  probablity=[True,False]
  break_ties=[False,True]
  degree=[2,3,4,5,6,7,8,9,10]
  gamma = ['scale','auto','float']
  kernel=['poly','rbf','sigmoid'] #exclude precomputed from this list as it is giving error
  return {'C':c,'tol':tol,'shrinking':shrinking,'probability':probablity,
          'break_ties':break_ties,'degree':degree,'gamma':gamma,'kernel':kernel}

def DT_CLASSIFIER():
  criterion=['gini','entropy']
  splitter=['best', 'random']
  max_features=['int','float','auto','sqrt','log2','None']
  return {'criterion':criterion,'splitter':splitter,'max_features':max_features}
  '''
  THis is a short description
  If int, then consider max_features features at each split.
  If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split. 
  If “auto”, then max_features=sqrt(n_features).
  If “sqrt”, then max_features=sqrt(n_features).
  If “log2”, then max_features=log2(n_features).
  If None, then max_features=n_features.
  '''

def RF_CLASSIFIER():
  bootstrap=[True,False]
  criterion=['gini','entropy']
  max_features=['int','float','auto','sqrt','log2','None']
  n_estimators=[10,20,30,40,50,60,70,80,90,100]
  oob_score=[True,False]
  warm_start=[False,True]
  return {'bootstrap':bootstrap,'criterion':criterion,'max_features':max_features,
          'n_estimators':n_estimators,'oob_score':oob_score,
          'warm_start':warm_start}


def KNN_CLASSIFIER():
  algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']
  # the metric 'wminkowski' is a weighted metric and therefore requires a weight metric
  # this metric can be used in the case of imbalanced class
  metric=['euclidean','manhattan','chebyshev','minkowski','seuclidean','mahalanobis']
  n_neighbors=[3,4,5,6,7,8,9,10]
  return {'algorithm':algorithm,'metric':metric,'n_neighbors':n_neighbors}





def GAUSSIAN_CLASSIFIER():
  multi_class=['one_vs_rest', 'one_vs_one']
  warm_start=[True,False]
  copy_X_train=[True,False]
  return {'multi_class':multi_class,
          'warm_start':warm_start,'copy_X_train':copy_X_train}
def RIDGE_CLASSIFIER():
  copy_X=[True,False]
  fit_intercept=[True,False]
  normalize = [True,False]
  random_state = [True,False]
  tol = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]
  alpha = [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1]
  solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']
  return {'copy_X':copy_X,'fit_intercept':fit_intercept,
          'normalize':normalize,'random_state':random_state,
          'tol':tol,'alpha':alpha,'solver':solver}
def LDA_CLASSIFIER():
  tol = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]
  solver=['svd', 'lsqr', 'eigen']
  shrinkage=['auto',float]
  store_covariance=[True,False]
  return {'tol':tol,'solver':solver,'shrinkage':shrinkage,
          'store_covariance':store_covariance}


def ADABOOST_CLASSIFIER():
  algorithm = ['SAMME', 'SAMME.R']
  learning_rate = [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1]
  n_estimators=[50,70,90,100,200,300,400]
  return {'algorithm':algorithm,'learning_rate':learning_rate,
          'n_estimators':n_estimators}

def GRADIENT_BOOSTING_CLASSIFIER():
  learning_rate = [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1]
  criterion = ['friedman_mse', 'mse', 'mae']
  loss = ['deviance', 'exponential']
  max_depth = [3,4,5,6,7,8,9,10]
  n_estimators = [40,50,60,70,80,90,100,200,300]
  tol = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]
  warm_start = [True,False]
  return {'learning_rate':learning_rate,
          'criterion':criterion,
          'loss':loss,'max_depth':max_depth,
          'n_estimators':n_estimators,'tol':tol,
          'warm_start':warm_start
          }



def QDA_CLASSIFIER():
  store_covariance = [True,False]
  tol = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]
  return  {'store_covariance':store_covariance,
           'tol':tol}
def ET_CLASSIFIER():
  bootstrap = [True,False]
  criterion = ['gini','entropy']
  max_features = ['auto', 'sqrt', 'log2']
  n_estimators = [40,60,80,100,200,300,400]
  oob_score = [True,False]
  warm_start = [True,False]
  return {'bootstrap':bootstrap,'criterion':criterion,'max_features':max_features,
          'n_estimators':n_estimators,'oob_score':oob_score,'warm_start':warm_start}

def XGB_CLASSIFIER():
  params={'booster':['gblinear','gbtree','dart'],'gamma':[1e-2,1e-1,0.2,0.4,0.6,0.8,1.0,2.0,4.0,6.0,8.0,10.0,15.0,20.0],
           'importance_type':['gain','cover'],'leaning_rate':[1e-3,1e-2,1e-1,0.2,0.3,0.4,0.5,0.9,1.0],
           'max_depth':[1,2,3,4,5,6,7,8,9,10],'min_child_weight':[1,2,4,5,3,6,7,8,9,10],'n_estimators':[100,200,300,400,500],
           'reg_alpha':[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],'reg_lambda':[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0],
        'objective':['reg:logistic','binary:logistic','binary:hinge','binary:logitraw','multi:softmax']}
  
  return params

def LGB_CLASSIFIER():
  boosting_type = ['gbdt','dart','goss','rf']
  importance_type = ['split','gain']
  learning_rate = [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1]
  n_estimators = [40,60,80,100,200,300]
  objective = ['binary','multiclass']
  reg_alpha = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
  reg_lambda = [1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0]
  silent = [True,False]
  
  return {'boosting_type':boosting_type,'importance_type':importance_type,
          'learning_rate':learning_rate,'n_estimators':n_estimators,
          'objective':objective,'reg_alpha':reg_alpha,'reg_lambda':reg_lambda,
          'silent':silent}




hypertune_model('lgb_classifier',x_train,y_train)
#catboost and naive bayes has not hyperparameters to tune

"""# **Dimensionality Reduction**"""

def reduce_dimension(reduced_dimension:int,x_train,x_test,algo:str='PCA',kernel:str='rbf'):
  if algo == 'PCA':
    reduced_data=Apply_PCA(reduced_dimension,x_train,x_test)
  elif algo == 'KPCA':
    reduced_data=Apply_KernelPCA(reduced_dimension,kernel,x_train,x_test)
  elif algo == 'LDA':
    reduced_data=Apply_LDA(reduced_dimension,x_train,x_test)
  return reduced_data

def Apply_PCA(reduced_dimension:int,x_train,x_test):
  from sklearn.decomposition import PCA
  pca=PCA(n_components=reduced_dimension)#n_component=reduced dimension of dataset
  x_train=pca.fit_transform(x_train)
  x_test=pca.transform(x_test)
  return {'x_train':x_train,'x_test':x_test}

def Apply_KernelPCA(reduced_dimension:int,kernel:str,x_train,x_test):
  from sklearn.decomposition import KernelPCA
  pca=KernelPCA(n_components=reduced_dimension,kernel=kernel)
  x_train=pca.fit_transform(x_train)
  x_test=pca.transform(x_test)
  return {'x_train':x_train,'x_test':x_test}

def Apply_LDA(reduced_dimension:int,x_train,x_test):
  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
  lda=LDA(n_components=reduced_dimension)#reduced dimension of dataset
  x_train=lda.fit_transform(x_train,y_train)#we need to pass dependent variable as well
  x_test=lda.transform(x_test)
  return {'x_train':x_train,'x_test':x_test}

print(f"The original number of independent features in our dataset are {data.shape[1]-1}")

reduced_datasetPCA = reduce_dimension(30,x_train,x_test,'PCA','rbf')
print(reduced_datasetPCA)

reduced_datasetKPCA  = reduce_dimension(30,x_train,x_test,'KPCA','rbf')
print(reduced_datasetKPCA)

reduced_datasetLDA = reduce_dimension(30,x_train,x_test,'LDA')
print(reduced_datasetLDA)

# Hom to compute class weights for an imbalanced dataset
from sklearn.utils import class_weight
class_weights = class_weight.compute_class_weight('balanced',
                                                 np.unique(y_train),
                                                 y_train)
print(class_weights)

#Note some models can deal with imbalanced data themselves and we don't need 
# to apply weights to them

#Classification Imbalanced

def get_models(x_train,y_train,class_weight):
  LogisticRegressor = ImbalancedLogisitcRegression(x_train,y_train,class_weight)

  LinearSVCClassifier = ImbalancedSupportVectorClassifier(x_train,y_train,class_weight)

  KernelSVCClassifier = ImbalancedKernelSVC(x_train,y_train,class_weight)
 
  DecisionTreeClassifier = ImbalancedDecisionTreeClassifier(x_train,y_train,class_weight)
 
  RandomForestClassifer = ImbalancedRandomForestClassifier(x_train,y_train,class_weight)

  RidgeClassifier = ImbalanceRidgeClassifier(x_train,y_train,class_weight)
  
  ExtraTreeClassifier = ImbalancedExtraTreeClassifier(x_train,y_train,class_weight)

  LgbmClassifier = ImbalancedLGBMCLASSIFIER(x_train,y_train,class_weight)


  return {'logisticRegression':LogisticRegressor,'SVC':LinearSVCClassifier,
          'KernelSVC':KernelSVCClassifier,
          'DTClassifier':DecisionTreeClassifier,'RFClassifier':RandomForestClassifer,
          'RidgeClassifier':RidgeClassifier,'ETClassifier':ExtraTreeClassifier,
          'LgbmClassifier':LgbmClassifier}








def ImbalancedLogisitcRegression(x_train,y_train,class_weights):
  from sklearn.linear_model import LogisticRegression
  classifier = LogisticRegression(class_weight=class_weights)
  classifier.fit(x_train,y_train)
  return classifier

def ImbalancedSupportVectorClassifier(x_train,y_train,class_weights):
  from sklearn.svm import SVC
  classifier = SVC(kernel='linear',class_weight=class_weights)
  classifier.fit(x_train,y_train)
  return classifier

def ImbalancedKernelSVC(x_train,y_train,class_weights):
  from sklearn.svm import SVC
  classifier = SVC(kernel = 'rbf',class_weight=class_weights)
  classifier.fit(x_train,y_train)
  return classifier


# naive bayes classifier has no such hyperparameter
#KNN has no class weigt hyper parametre

def ImbalancedDecisionTreeClassifier(x_train,y_train,class_weights):
  from sklearn.tree import DecisionTreeClassifier
  classifier = DecisionTreeClassifier(criterion = 'gini', random_state = 0
                                      ,class_weight=class_weights)
  classifier.fit(x_train, y_train)
  return classifier

def ImbalancedRandomForestClassifier(x_train,y_train,class_weights):
  from sklearn.ensemble import RandomForestClassifier
  classifier = RandomForestClassifier(n_estimators = 10, criterion = 'gini',
                                      random_state = 0,class_weight = class_weights)
  classifier.fit(x_train, y_train)
  return classifier

# gaussian  classsifier have no weight hyper parameter

def ImbalanceRidgeClassifier(x_train,y_train,class_weights):
  from sklearn.linear_model import RidgeClassifier
  classifier = RidgeClassifier(class_weight = class_weights)
  classifier.fit(x_train,y_train)
  return classifier


# LDA classifier and adaboost,qda,gradient boosting classifier have no class weight hyper parameter

def ImbalancedExtraTreeClassifier(x_train,y_train,class_weights):
  from sklearn.ensemble import ExtraTreesClassifier
  classifier = ExtraTreesClassifier(n_estimators=100,random_state=42,
                                    class_weight = class_weights)
  classifier.fit(x_train,y_train)
  return classifier

# xgb classifier have no weights hyperparameter

def ImbalancedLGBMCLASSIFIER(x_train,y_train,class_weights):
   from lightgbm import LGBMClassifier
   classifier = LGBMClassifier(class_weight = class_weights)
   classifier.fit(x_train,y_train)
   return classifier

class_weight = {0:class_weights[0],1:class_weights[1]}
imblancedModels = get_models(x_train,y_train,class_weight)

imbalanced_predictions = make_predictions(imblancedModels)

compare_results(imbalanced_predictions)

visualize_models(y_test,imbalanced_predictions)

prepare_confusion_matrix(imblancedModels)

ROC_Curve(imbalanced_predictions)

AUC_curve(imbalanced_predictions)

imbalanced_scores = matric_evaluation_of_models(imblancedModels)

ImbalncedDataFrameScores = prepare_df_model_evaluation(imbalanced_scores)

display(ImbalncedDataFrameScores)

imblanced_confusion_score = get_confusion_params(imbalanced_predictions)

imbalancedSpecificitySenstivity = specificity_senstivity(imblanced_confusion_score)

print(imbalancedSpecificitySenstivity)

#Before passing in the new test data pass it tohrough the same scaling which was applied to train adn test data

#Check you model for overfitting and underfitting